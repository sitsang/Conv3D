{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/team12/team12/data/gear_images_normalized/axes : 0\n",
      "/home/team12/team12/data/gear_images_normalized/boots : 1\n",
      "/home/team12/team12/data/gear_images_normalized/carabiners : 2\n",
      "/home/team12/team12/data/gear_images_normalized/crampons : 3\n",
      "/home/team12/team12/data/gear_images_normalized/gloves : 4\n",
      "/home/team12/team12/data/gear_images_normalized/hardshell_jackets : 5\n",
      "/home/team12/team12/data/gear_images_normalized/harnesses : 6\n",
      "/home/team12/team12/data/gear_images_normalized/helmets : 7\n",
      "/home/team12/team12/data/gear_images_normalized/insulated_jackets : 8\n",
      "/home/team12/team12/data/gear_images_normalized/pulleys : 9\n",
      "/home/team12/team12/data/gear_images_normalized/rope : 10\n",
      "/home/team12/team12/data/gear_images_normalized/tents : 11\n",
      "(2122, 128, 128, 3)\n",
      "(2122,)\n",
      "Split...\n",
      "(1697, 128, 128, 3)\n",
      "(1697, 12)\n",
      "(425, 128, 128, 3)\n",
      "(425, 12)\n",
      "Start ...\n",
      "model step 1\n",
      "model step 2\n",
      "WARNING:tensorflow:From <ipython-input-1-d48953541b95>:70: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "model step 3\n",
      "epoch:0\n",
      "Cost after epoch 0: 3.166725\n",
      "epoch:1\n",
      "Cost after epoch 1: 2.004362\n",
      "epoch:2\n",
      "Cost after epoch 2: 1.548947\n",
      "epoch:3\n",
      "Cost after epoch 3: 1.198862\n",
      "epoch:4\n",
      "Cost after epoch 4: 1.067594\n",
      "epoch:5\n",
      "Cost after epoch 5: 0.893757\n",
      "epoch:6\n",
      "Cost after epoch 6: 0.843330\n",
      "epoch:7\n",
      "Cost after epoch 7: 0.794928\n",
      "epoch:8\n",
      "Cost after epoch 8: 0.786151\n",
      "epoch:9\n",
      "Cost after epoch 9: 0.723801\n",
      "epoch:10\n",
      "Cost after epoch 10: 0.656201\n",
      "epoch:11\n",
      "Cost after epoch 11: 0.782500\n",
      "epoch:12\n",
      "Cost after epoch 12: 0.732856\n",
      "epoch:13\n",
      "Cost after epoch 13: 0.618530\n",
      "epoch:14\n",
      "Cost after epoch 14: 0.585915\n",
      "epoch:15\n",
      "Cost after epoch 15: 0.626685\n",
      "epoch:16\n",
      "Cost after epoch 16: 0.568144\n",
      "epoch:17\n",
      "Cost after epoch 17: 0.583157\n",
      "epoch:18\n",
      "Cost after epoch 18: 0.571945\n",
      "epoch:19\n",
      "Cost after epoch 19: 0.536121\n",
      "epoch:20\n",
      "Cost after epoch 20: 0.574800\n",
      "epoch:21\n",
      "Cost after epoch 21: 0.578833\n",
      "epoch:22\n",
      "Cost after epoch 22: 0.541705\n",
      "epoch:23\n",
      "Cost after epoch 23: 0.550100\n",
      "epoch:24\n",
      "Cost after epoch 24: 0.595106\n",
      "epoch:25\n",
      "Cost after epoch 25: 0.554287\n",
      "epoch:26\n",
      "Cost after epoch 26: 0.557030\n",
      "epoch:27\n",
      "Cost after epoch 27: 0.484595\n",
      "epoch:28\n",
      "Cost after epoch 28: 0.489927\n",
      "epoch:29\n",
      "Cost after epoch 29: 0.569692\n",
      "epoch:30\n",
      "Cost after epoch 30: 0.517398\n",
      "epoch:31\n",
      "Cost after epoch 31: 0.448885\n",
      "epoch:32\n",
      "Cost after epoch 32: 0.465160\n",
      "epoch:33\n",
      "Cost after epoch 33: 0.481404\n",
      "epoch:34\n",
      "Cost after epoch 34: 0.485147\n",
      "epoch:35\n",
      "Cost after epoch 35: 0.476772\n",
      "epoch:36\n",
      "Cost after epoch 36: 0.489534\n",
      "epoch:37\n",
      "Cost after epoch 37: 0.501997\n",
      "epoch:38\n",
      "Cost after epoch 38: 0.517140\n",
      "epoch:39\n",
      "Cost after epoch 39: 0.460342\n",
      "epoch:40\n",
      "Cost after epoch 40: 0.435388\n",
      "epoch:41\n",
      "Cost after epoch 41: 0.510628\n",
      "epoch:42\n",
      "Cost after epoch 42: 0.436950\n",
      "epoch:43\n",
      "Cost after epoch 43: 0.426383\n",
      "epoch:44\n",
      "Cost after epoch 44: 0.488627\n",
      "epoch:45\n",
      "Cost after epoch 45: 0.456427\n",
      "epoch:46\n",
      "Cost after epoch 46: 0.435280\n",
      "epoch:47\n",
      "Cost after epoch 47: 0.405890\n",
      "epoch:48\n",
      "Cost after epoch 48: 0.450196\n",
      "epoch:49\n",
      "Cost after epoch 49: 0.413255\n",
      "epoch:50\n",
      "Cost after epoch 50: 0.412519\n",
      "epoch:51\n",
      "Cost after epoch 51: 0.419897\n",
      "epoch:52\n",
      "Cost after epoch 52: 0.399416\n",
      "epoch:53\n",
      "Cost after epoch 53: 0.401947\n",
      "epoch:54\n",
      "Cost after epoch 54: 0.371434\n",
      "epoch:55\n",
      "Cost after epoch 55: 0.398825\n",
      "epoch:56\n",
      "Cost after epoch 56: 0.404034\n",
      "epoch:57\n",
      "Cost after epoch 57: 0.406256\n",
      "epoch:58\n",
      "Cost after epoch 58: 0.423144\n",
      "epoch:59\n",
      "Cost after epoch 59: 0.406789\n",
      "epoch:60\n",
      "Cost after epoch 60: 0.406206\n",
      "epoch:61\n",
      "Cost after epoch 61: 0.379237\n",
      "epoch:62\n",
      "Cost after epoch 62: 0.361373\n",
      "epoch:63\n",
      "Cost after epoch 63: 0.362416\n",
      "epoch:64\n",
      "Cost after epoch 64: 0.363547\n",
      "epoch:65\n",
      "Cost after epoch 65: 0.424070\n",
      "epoch:66\n",
      "Cost after epoch 66: 0.404655\n",
      "epoch:67\n",
      "Cost after epoch 67: 0.378600\n",
      "epoch:68\n",
      "Cost after epoch 68: 0.402326\n",
      "epoch:69\n",
      "Cost after epoch 69: 0.392938\n",
      "epoch:70\n",
      "Cost after epoch 70: 0.390551\n",
      "epoch:71\n",
      "Cost after epoch 71: 0.369510\n",
      "epoch:72\n",
      "Cost after epoch 72: 0.386807\n",
      "epoch:73\n",
      "Cost after epoch 73: 0.366054\n",
      "epoch:74\n",
      "Cost after epoch 74: 0.364330\n",
      "epoch:75\n",
      "Cost after epoch 75: 0.378137\n",
      "epoch:76\n",
      "Cost after epoch 76: 0.372808\n",
      "epoch:77\n",
      "Cost after epoch 77: 0.370659\n",
      "epoch:78\n",
      "Cost after epoch 78: 0.374566\n",
      "epoch:79\n",
      "Cost after epoch 79: 0.342495\n",
      "epoch:80\n",
      "Cost after epoch 80: 0.360661\n",
      "epoch:81\n",
      "Cost after epoch 81: 0.360943\n",
      "epoch:82\n",
      "Cost after epoch 82: 0.345236\n",
      "epoch:83\n",
      "Cost after epoch 83: 0.352748\n",
      "epoch:84\n",
      "Cost after epoch 84: 0.348597\n",
      "epoch:85\n",
      "Cost after epoch 85: 0.361109\n",
      "epoch:86\n",
      "Cost after epoch 86: 0.357463\n",
      "epoch:87\n",
      "Cost after epoch 87: 0.329052\n",
      "epoch:88\n",
      "Cost after epoch 88: 0.328814\n",
      "epoch:89\n",
      "Cost after epoch 89: 0.330705\n",
      "epoch:90\n",
      "Cost after epoch 90: 0.345438\n",
      "epoch:91\n",
      "Cost after epoch 91: 0.361220\n",
      "epoch:92\n",
      "Cost after epoch 92: 0.379022\n",
      "epoch:93\n",
      "Cost after epoch 93: 0.327156\n",
      "epoch:94\n",
      "Cost after epoch 94: 0.323374\n",
      "epoch:95\n",
      "Cost after epoch 95: 0.332426\n",
      "epoch:96\n",
      "Cost after epoch 96: 0.359348\n",
      "epoch:97\n",
      "Cost after epoch 97: 0.365985\n",
      "epoch:98\n",
      "Cost after epoch 98: 0.317103\n",
      "epoch:99\n",
      "Cost after epoch 99: 0.306949\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23b7a2d8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.8674131\n",
      "Test Accuracy: 0.84\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n",
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_H0, n_W0, n_C0))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, n_y))\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "        \n",
    "    W1 = tf.get_variable(\"W1\", [3, 3, 3, 32], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", [3, 3, 32, 64], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W3 = tf.get_variable(\"W3\", [3, 3, 64, 128], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "\n",
    "    parameters = {\"W1\": W1, \"W2\": W2, \"W3\": W3}\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    Z1 = tf.layers.batch_normalization(Z1)\n",
    "    # add batch normalization\n",
    "    #Z1 = tf.nn.bias_add(Z1, tf.Variable(tf.random_normal([Z1.shape.as_list()[0]])))\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    Z2 = tf.layers.batch_normalization(Z2)\n",
    "    # add batch normalization\n",
    "    #Z2 = tf.nn.bias_add(Z2, tf.Variable(tf.random_normal([Z2.shape.as_list()[0]])))\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    Z3 = tf.nn.conv2d(P2, W3, strides = [1,1,1,1], padding = 'SAME')\n",
    "    Z3 = tf.layers.batch_normalization(Z3)\n",
    "    # add batch normalization\n",
    "    #Z2 = tf.nn.bias_add(Z2, tf.Variable(tf.random_normal([Z2.shape.as_list()[0]])))\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    P3 = tf.nn.max_pool(A3, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    # add anohter layer\n",
    "\n",
    "    P4 = tf.nn.dropout(P3, 0.1)\n",
    "    P  = tf.contrib.layers.flatten(P4)\n",
    "    Z4 = tf.contrib.layers.fully_connected(P, 12, activation_fn=None)\n",
    "\n",
    "    return Z4\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "\n",
    "    return cost\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.01,\n",
    "          num_epochs=200, minibatch_size=64, print_cost=True):\n",
    "\n",
    "    print('model step 1')\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    print('model step 2')\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('model step 3')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"epoch:\" + str(epoch))\n",
    "            \n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "                #print(\"minibatch:\" + str(minibatch))\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "            \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters\n",
    "    \n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 128, seed = 0):\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "    #shuffled_X, shuffled_Y = shuffle(X, Y, random_state=seed)\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#img_root = '/Users/zhigangyao/workspace/openhack/gear_images_normalized'\n",
    "img_root = '/home/team12/team12/data/gear_images_normalized'\n",
    "#img_root = '/home/team12/team12/data/gear_images_equalize'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(img_root) if os.path.isdir(os.path.join(img_root,o))]\n",
    "img_dirs.sort()\n",
    "x = []\n",
    "y = []\n",
    "category = 0\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir + \" : \" + str(category))\n",
    "    count = 0\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    for img_file in img_files:\n",
    "        #print(img_dir + '/' + img_file)\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        x.append(np.array(Image.open(image_path)))\n",
    "        y.append(category)\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "        count += 1\n",
    "    category += 1\n",
    "\n",
    "X = np.array(x)\n",
    "#Y = tf.one_hot(np.array(y), 12)\n",
    "Y = np.array(y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print('Split...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n",
    "#Y_train = tf.one_hot(y_train, 12)\n",
    "#Y_test = tf.one_hot(y_test, 12)\n",
    "Y_train = convert_to_one_hot(y_train, 12).T\n",
    "Y_test = convert_to_one_hot(y_test, 12).T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Start ...')\n",
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#img_root = '/Users/zhigangyao/workspace/openhack/gear_images_normalized'\n",
    "#img_root = '/home/team12/team12/data/gear_images_normalized'\n",
    "img_root = '/home/team12/team12/data/gear_images_equalize'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(img_root) if os.path.isdir(os.path.join(img_root,o))]\n",
    "img_dirs.sort()\n",
    "x = []\n",
    "y = []\n",
    "category = 0\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir + \" : \" + str(category))\n",
    "    count = 0\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    for img_file in img_files:\n",
    "        #print(img_dir + '/' + img_file)\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        x.append(np.array(Image.open(image_path)))\n",
    "        y.append(category)\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "        count += 1\n",
    "    category += 1\n",
    "\n",
    "X = np.array(x)\n",
    "#Y = tf.one_hot(np.array(y), 12)\n",
    "Y = np.array(y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print('Split...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n",
    "#Y_train = tf.one_hot(y_train, 12)\n",
    "#Y_test = tf.one_hot(y_test, 12)\n",
    "Y_train = convert_to_one_hot(y_train, 12).T\n",
    "Y_test = convert_to_one_hot(y_test, 12).T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Start ...')\n",
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#img_root = '/Users/zhigangyao/workspace/openhack/gear_images_normalized'\n",
    "img_root = '/home/team12/team12/data/gear_images_normalized'\n",
    "#img_root = '/home/team12/team12/data/gear_images_equalize'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(img_root) if os.path.isdir(os.path.join(img_root,o))]\n",
    "img_dirs.sort()\n",
    "x = []\n",
    "y = []\n",
    "category = 0\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir + \" : \" + str(category))\n",
    "    count = 0\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    for img_file in img_files:\n",
    "        #print(img_dir + '/' + img_file)\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        x.append(np.array(Image.open(image_path)))\n",
    "        y.append(category)\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "        count += 1\n",
    "    category += 1\n",
    "\n",
    "X = np.array(x)\n",
    "#Y = tf.one_hot(np.array(y), 12)\n",
    "Y = np.array(y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print('Split...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n",
    "#Y_train = tf.one_hot(y_train, 12)\n",
    "#Y_test = tf.one_hot(y_test, 12)\n",
    "Y_train = convert_to_one_hot(y_train, 12).T\n",
    "Y_test = convert_to_one_hot(y_test, 12).T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Start ...')\n",
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
