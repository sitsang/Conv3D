{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client, urllib.request, urllib.parse, urllib.error, base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    # Request headers\n",
    "    'Content-Type': 'application/json',\n",
    "    'Prediction-key': '009281becef44f2c85dd96cd749d56ea',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = urllib.parse.urlencode({\n",
    "    # Request parameters\n",
    "    'iterationId': '22f47df0-85a5-42e2-9e0c-d73a1591ad1d',\n",
    "    'application': 'task1',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn = http.client.HTTPSConnection('southcentralus.api.cognitive.microsoft.com')\n",
    "    conn.request(\"POST\", \"/customvision/v2.0/Prediction/dbb69137-acbf-4209-88dd-3220c4011eb3/url?%s\" % params, '{\"Url\": \"http://img.cdn.mountainwarehouse.com/product/025374/025374_pur_featherweight_down_womens_jacket__wms_aw17_2.jpg\"}', headers)\n",
    "    response = conn.getresponse()\n",
    "    data = response.read()\n",
    "    print(data)\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "desired_size = 128\n",
    "from matplotlib.pyplot import imshow\n",
    "new_img = Image.new(\"RGB\",(1,1),(0,0,0))\n",
    "\n",
    "def process_image(old_im_pth,new_im_path):\n",
    "    im = Image.open(old_im_pth)\n",
    "    old_size = im.size  \n",
    "\n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    "   \n",
    "    im = im.resize(new_size, Image.ANTIALIAS)\n",
    "   \n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size), \"white\")\n",
    "    new_im.paste(im, ((desired_size-new_size[0])//2,\n",
    "                     (desired_size-new_size[1])//2))\n",
    "    new_im.save(new_im_path, \"JPEG\")\n",
    "    \n",
    "def normalize(arr):\n",
    "    \"\"\"\n",
    "    Linear normalization\n",
    "    http://en.wikipedia.org/wiki/Normalization_%28image_processing%29\n",
    "    \"\"\"\n",
    "    arr = arr.astype('float')\n",
    "    # Do not touch the alpha channel\n",
    "    for i in range(3):\n",
    "        minval = arr[...,i].min()\n",
    "        maxval = arr[...,i].max()\n",
    "        if minval != maxval:\n",
    "            arr[...,i] -= minval\n",
    "            arr[...,i] *= (255.0/(maxval-minval))\n",
    "    return arr\n",
    "\n",
    "def save_equalize(image_path, new_image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img.show\n",
    "    plt.imshow(img)\n",
    "    plt.title('Before Equalize')\n",
    "    plt.show()\n",
    "    \n",
    "    #histogram\n",
    "    mp_img=mpimg.imread(image_path)\n",
    "    plt.style.use('seaborn-white')\n",
    "    plt.hist(mp_img.ravel(), 256, [0, 256])\n",
    "    plt.show()\n",
    "    \n",
    "    new_img = ImageOps.equalize(img)\n",
    "    plt.imshow(new_img)\n",
    "    plt.title('After Equalize')\n",
    "    plt.show()\n",
    "\n",
    "    #histogram\n",
    "    mp_img=mpimg.imread(new_image_path)\n",
    "    plt.style.use('seaborn-white')\n",
    "    plt.hist(mp_img.ravel(), 256, [0, 256])\n",
    "    plt.show()\n",
    "\n",
    "def save_normalize(image_path, new_image_path):\n",
    "    global new_img\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    arr = np.array(img)\n",
    "    imshow(arr)\n",
    "    new_img = Image.fromarray(normalize(arr).astype('uint8'),'RGB')\n",
    "    new_img.save(new_image_path)\n",
    "\n",
    "img_root = '/home/team12/team12/data/gear_images'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(img_root) if os.path.isdir(os.path.join(img_root,o))]\n",
    "for img_dir in img_dirs:\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    for img_file in img_files:\n",
    "    img_dir = img_root + \"/boots\"\n",
    "    img_file = \"733952.jpeg\"\n",
    "    print(img_dir + '/' + img_file)\n",
    "    image_path = img_dir + '/' + img_file\n",
    "\n",
    "    #step 1 process image with pad and resize - completed\n",
    "    save_dir = img_dir + '/step1/'\n",
    "    new_image_path_step1 = save_dir + img_file\n",
    "\n",
    "    #step 2a is normalize\n",
    "    save_dir = img_dir + '/step3/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    new_image_path_step = save_dir + img_file\n",
    "    #process_image(image_path,new_image_path_step)\n",
    "    save_normalize(new_image_path_step1, new_image_path_step)\n",
    "    print('Step 3 normalized and saved to: ' + new_image_path_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to2D(arr):\n",
    "    x, y, z = arr.shape\n",
    "    indices = np.vstack(np.unravel_index(np.arange(x*y), (y, x))).T\n",
    "    return np.hstack((arr.reshape(x*y, z), indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/team12/team12/data/gear_images_normalized/axes : 0\n",
      "/home/team12/team12/data/gear_images_normalized/boots : 1\n",
      "/home/team12/team12/data/gear_images_normalized/carabiners : 2\n",
      "/home/team12/team12/data/gear_images_normalized/crampons : 3\n",
      "/home/team12/team12/data/gear_images_normalized/gloves : 4\n",
      "/home/team12/team12/data/gear_images_normalized/hardshell_jackets : 5\n",
      "/home/team12/team12/data/gear_images_normalized/harnesses : 6\n",
      "/home/team12/team12/data/gear_images_normalized/helmets : 7\n",
      "/home/team12/team12/data/gear_images_normalized/insulated_jackets : 8\n",
      "/home/team12/team12/data/gear_images_normalized/pulleys : 9\n",
      "/home/team12/team12/data/gear_images_normalized/rope : 10\n",
      "/home/team12/team12/data/gear_images_normalized/tents : 11\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_root = '/home/team12/team12/data/gear_images_normalized'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(img_root) if os.path.isdir(os.path.join(img_root,o))]\n",
    "img_dirs.sort()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "category = 0\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir + \" : \" + str(category))\n",
    "    count = 0\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    for img_file in img_files:\n",
    "        #print(img_dir + '/' + img_file)\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        x.append(np.array(Image.open(image_path).convert(\"RGB\")))\n",
    "        y.append(category)\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "        count += 1\n",
    "    category += 1\n",
    "\n",
    "X = np.array(x) #.reshape(len(x), -1)\n",
    "Y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "X_train = (X_train/255).astype('float32')\n",
    "X_test = (X_test/255).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#predictions = clf.predict(X_test)\n",
    "#plt.scatter(y_test, predictions)\n",
    "#plt.xlabel('True Values')\n",
    "#plt.ylabel('Predictions')\n",
    "#plt.show()\n",
    "#print(\"Score:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import tree\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#clf = tree.DecisionTreeClassifier(max_depth=11)\n",
    "#clf = RandomForestClassifier()\n",
    "#clf = ExtraTreesClassifier(n_estimators=22,max_depth=11,random_state=40)\n",
    "\n",
    "#clf = clf.fit(X_train, y_train)\n",
    "#predictions = clf.predict(X_test)\n",
    "#print(\"Score:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import graphviz \n",
    "#dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "#graph = graphviz.Source(dot_data) \n",
    "#graph.render(\"gears\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-17dc350c2579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#with tf.device('/gpu:0'):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#model.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "from keras.layers import Dense,Activation,Flatten,Conv2D, MaxPooling2D,Dropout,Reshape, BatchNormalization\n",
    "\n",
    "model.add(Conv2D(12, (8,8), activation='relu', input_shape=(128,128,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (16,16), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.01))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "        optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "#with tf.device('/gpu:0'):\n",
    "model.fit(X_train, to_categorical(y_train), epochs=5)\n",
    "\n",
    "#model.summary()\n",
    "model.evaluate(X_test, to_categorical(y_test), batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17948043956440504245\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "from keras import backend as K\n",
    "\n",
    "num_cores = 1\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "    inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "    device_count = {'CPU' : 1, 'GPU' : 2})\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.models import load_model\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import flask\n",
    "import io\n",
    "\n",
    "# initialize our Flask application and the Keras model\n",
    "app = flask.Flask(__name__)\n",
    "model = None\n",
    "lookup = {0: 'axes', 1: 'boots', 2: 'carabiners', 3: 'crampons', 4: 'gloves', 5: 'hardshell_jackets',\n",
    "          6: 'harnesses', 7: 'helmets', 8: 'insulated_jackets', 9: 'pulleys', 10: 'rope', 11: 'tents'}\n",
    "\n",
    "\n",
    "def load_model_s():\n",
    "    # load the pre-trained Keras model (here we are using a model\n",
    "    # pre-trained on ImageNet and provided by Keras, but you can\n",
    "    # substitute in your own networks just as easily)\n",
    "    global model\n",
    "    #model = ResNet50(weights=\"imagenet\")\n",
    "    model = load_model('cnn-aw-model.h5')\n",
    "\n",
    "\n",
    "def prepare_image(image, target):\n",
    "    # if the image mode is not RGB, convert it\n",
    "    if image.mode != \"RGB\":\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "    # resize the input image and preprocess it\n",
    "    image = image.resize(target)\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "    # return the processed image\n",
    "    return image\n",
    "\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    # initialize the data dictionary that will be returned from the\n",
    "    # view\n",
    "    data = {\"success\": False}\n",
    "\n",
    "    # ensure an image was properly uploaded to our endpoint\n",
    "    if flask.request.method == \"POST\":\n",
    "        if flask.request.files.get(\"image\"):\n",
    "            # read the image in PIL format\n",
    "            image = flask.request.files[\"image\"].read()\n",
    "            image = Image.open(io.BytesIO(image))\n",
    "\n",
    "            # preprocess the image and prepare it for classification\n",
    "            image = prepare_image(image, target=(128, 128))\n",
    "\n",
    "            # classify the input image and then initialize the list\n",
    "            # of predictions to return to the client\n",
    "            preds = model.predict(image)[0]\n",
    "            #results = imagenet_utils.decode_predictions(preds)\n",
    "            #preds = preds.astype('uint8')\n",
    "            print(preds)\n",
    "            data[\"predictions\"] = np.array_str(preds)\n",
    "\n",
    "            # loop over the results and add them to the list of\n",
    "            # returned predictions\n",
    "            # for (imagenetID, label, prob) in preds[0]:\n",
    "            #           r = {\"label\": label, \"probability\": float(prob)}\n",
    "     #          data[\"predictions\"].append(r)\n",
    "\n",
    "            # indicate that the request was a success\n",
    "            data[\"success\"] = True\n",
    "\n",
    "    # return the data dictionary as a JSON response\n",
    "    return flask.jsonify(data)\n",
    "\n",
    "\n",
    "# if this is the main thread of execution first load the model and\n",
    "# then start the server\n",
    "if __name__ == \"__main__\":\n",
    "    print((\"* Loading Keras model and Flask starting server...\"\n",
    "           \"please wait until server has fully started\"))\n",
    "    load_model_s()\n",
    "    app.run(host='0.0.0.0:5002')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
