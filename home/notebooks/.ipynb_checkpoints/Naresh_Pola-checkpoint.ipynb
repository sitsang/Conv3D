{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: pip: command not found\r\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'azure.cognitiveservices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d5afc78080fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install azure.cognitiveservices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mazure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcognitiveservices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mazure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcognitiveservices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustomvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageUrlCreateEntry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'azure.cognitiveservices'"
     ]
    }
   ],
   "source": [
    "\n",
    "from azure.cognitiveservices.vision.customvision.training import training_api\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageUrlCreateEntry\n",
    "\n",
    "# Replace with a valid key\n",
    "training_key = \"46af541243884e65aad3af90b74f46e7\"\n",
    "prediction_key = \"c7e65eff57ae4db59f24525bd69ac61d\"\n",
    "\n",
    "trainer = training_api.TrainingApi(training_key)\n",
    "\n",
    "# Create a new project\n",
    "print (\"Creating project...\")\n",
    "project = trainer.create_project(\"MyMNISTCustomVision\")\n",
    "\n",
    "four_tag = trainer.create_tag(project.id, \"Insulated Jackets\")\n",
    "eight_tag = trainer.create_tag(project.id, \"Hardshell Jackets\")\n",
    "\n",
    "base_image_url = \"https://raw.githubusercontent.com/Microsoft/Cognitive-CustomVision-Windows/master/Samples/\"\n",
    "\n",
    "print (\"Adding images...\")\n",
    "#for image_num in range(1,4):\n",
    "#    image_url = base_image_url + \"MNIST/4/four_{}.png\".format(image_num)\n",
    "#    #trainer.create_images_from_urls(project.id, [ ImageUrlCreateEntry(url=image_url, tag_ids=[ four_tag.id ] ) ])\n",
    "#\ttrainer.create_images_from_files(project.id, [ ImageFileCreateEntry(Contents=image_url, Name=, tag_ids=[ hemlock_tag.id ] ) ])\n",
    "\n",
    "#for image_num in range(1,10):\n",
    "#    image_url = base_image_url + \"MNIST/8/{}.png\".format(image_num)\n",
    "#    trainer.create_images_from_urls(project.id, [ ImageUrlCreateEntry(url=image_url, tag_ids=[ eight_tag.id ] ) ])\n",
    "\n",
    "\n",
    "# Alternatively, if the images were on disk in a folder called Images alongside the sample.py, then\n",
    "# they can be added by using the following:\n",
    "#\n",
    "import os\n",
    "hemlock_dir = \"/home/team12/team12/data/gear_images/insulated_jackets/\"\n",
    "for image in os.listdir(os.fsencode(hemlock_dir)):\n",
    "    with open(hemlock_dir + \"\\\\\" + os.fsdecode(image), mode=\"rb\") as img_data: \n",
    "        trainer.create_images_from_data(project.id, img_data, [ four_tag.id ])\n",
    "\n",
    "cherry_dir = \"/home/team12/team12/data/gear_images/hardshell_jackets\"\n",
    "for image in os.listdir(os.fsencode(cherry_dir)):\n",
    "    with open(cherry_dir + \"\\\\\" + os.fsdecode(image), mode=\"rb\") as img_data: \n",
    "        trainer.create_images_from_data(project.id, img_data, [ eight_tag.id ])\n",
    "\n",
    "import time\n",
    "\n",
    "print (\"Training...\")\n",
    "print(project.id)\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(1)\n",
    "\n",
    "# The iteration is now trained. Make it the default project endpoint\n",
    "trainer.update_iteration(project.id, iteration.id, is_default=True)\n",
    "print (\"Done!\")\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.prediction import prediction_endpoint\n",
    "from azure.cognitiveservices.vision.customvision.prediction.prediction_endpoint import models\n",
    "\n",
    "# Now there is a trained endpoint that can be used to make a prediction\n",
    "\n",
    "predictor = prediction_endpoint.PredictionEndpoint(prediction_key)\n",
    "\n",
    "#test_img_url = base_image_url + \"C:\\\\ETRM\\\\Python-WS\\\\Cognitive-CustomVision-Windows-master\\\\Samples\\\\MNIST/Test/17.png\"\n",
    "#results = predictor.predict_image_url(project.id, iteration.id, url=test_img_url)\n",
    "\n",
    "# Alternatively, if the images were on disk in a folder called Images alongside the sample.py, then\n",
    "# they can be added by using the following.\n",
    "#\n",
    "# Open the sample image and get back the prediction results.\n",
    "with open(\"/home/team12/team12/data/gear_images/hardshell_jackets/896903.jpeg\", mode=\"rb\") as test_data:\n",
    "     results = predictor.predict_image(project.id, test_data, iteration.id)\n",
    "\n",
    "# Display the results.\n",
    "for prediction in results.predictions:\n",
    "    print (\"\\t\" + prediction.tag_name + \": {0:.2f}%\".format(prediction.probability * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"id\":\"5788dcf6-f749-4387-98a2-aa4ca6ea1d0b\",\"project\":\"e6da02d6-eac5-475e-b891-1e2400519a69\",\"iteration\":\"22f47df0-85a5-42e2-9e0c-d73a1591ad1d\",\"created\":\"2018-05-23T15:21:46.5926506Z\",\"predictions\":[{\"probability\":0.99997884,\"tagId\":\"0b1f5b9b-038e-4eec-b20d-133850f2edd1\",\"tagName\":\"insulated jacket\"},{\"probability\":1.55497819E-05,\"tagId\":\"bb3320bc-d247-4c0a-8cd9-3355a7b30c6a\",\"tagName\":\"hardshell jacket\"}]}'\n"
     ]
    }
   ],
   "source": [
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "\n",
    "headers = {\n",
    "   # Request headers\n",
    "   'Content-Type': 'application/json',\n",
    "   'Prediction-key': '009281becef44f2c85dd96cd749d56ea',\n",
    "}\n",
    "\n",
    "params = urllib.parse.urlencode({\n",
    "   # Request parameters\n",
    "   'iterationId': '22f47df0-85a5-42e2-9e0c-d73a1591ad1d',\n",
    "   'application': 'team 12 hardshell',\n",
    "})\n",
    "\n",
    "try:\n",
    "   conn = http.client.HTTPSConnection('southcentralus.api.cognitive.microsoft.com')\n",
    "   conn.request(\"POST\", \"/customvision/v2.0/Prediction/dbb69137-acbf-4209-88dd-3220c4011eb3/url?%s\" % params, '{\"Url\": \"http://img.cdn.mountainwarehouse.com/product/025374/025374_pur_featherweight_down_womens_jacket__wms_aw17_2.jpg\"}', headers)\n",
    "   response = conn.getresponse()\n",
    "   data = response.read()\n",
    "   print(data)\n",
    "   conn.close()\n",
    "except Exception as e:\n",
    "   print(\"[Errno {0}] {1}\".format(e.errno, e.strerror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-17-f1bab184578a>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-f1bab184578a>\"\u001b[0;36m, line \u001b[0;32m34\u001b[0m\n\u001b[0;31m    img_root = '/home/team12/naresh/gear_images''\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "#import imutils\n",
    "import cv2 as cv\n",
    "import os\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join,basename\n",
    " \n",
    "from PIL import Image\n",
    "desired_size = 128\n",
    " \n",
    "def process_image(old_im_pth):\n",
    "    im = Image.open(old_im_pth)\n",
    "    old_size = im.size\n",
    " \n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    " \n",
    "    im = im.resize(new_size, Image.ANTIALIAS)\n",
    " \n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size), (255, 225, 255))\n",
    "    new_im.paste(im, ((desired_size-new_size[0])//2,\n",
    "                      (desired_size-new_size[1])//2))\n",
    "    return np.array(new_im)\n",
    " \n",
    "lookup = {'axes': 1, 'boots': 2, 'carabiners': 3, 'crampons': 4, 'gloves': 5, 'hardshell_jackets': 6, 'harnesses': 7, 'helmets': 8, 'insulated_jackets': 9, 'pulleys': 10, 'rope': 11, 'tents': 12}\n",
    "r_lookup = {1: 'axes', 2: 'boots', 3: 'carabiners', 4: 'crampons', 5: 'gloves', 6: 'hardshell_jackets', 7: 'harnesses', 8: 'helmets', 9: 'insulated_jackets', 10: 'pulleys' , 11: 'rope', 12: 'tents'}\n",
    "#img_root = '/home/team12/team12/data/gear_images_normalized'\n",
    "img_root = '/home/team12/naresh/gear_images'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(\n",
    "    img_root) if os.path.isdir(os.path.join(img_root, o))]\n",
    "class_index = 1\n",
    "dataset = np.empty((1, desired_size * desired_size * 3))\n",
    "labelset = np.empty(1)\n",
    "for img_dir in img_dirs:\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    image_label = np.full([len(img_files)], lookup[basename(img_dir)])\n",
    "    print(image_label)\n",
    "    image_data = np.empty([len(img_files), desired_size * desired_size * 3])\n",
    "    index = 0\n",
    "    for img_file in img_files:\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        dst = np.zeros(shape=(desired_size, desired_size))\n",
    "        image = process_image(image_path)\n",
    "        norm_image = cv.normalize(image, dst, 0, 255, cv.NORM_MINMAX)\n",
    "        image_data[index] = norm_image.flatten()\n",
    "        # print(image_data.shape)\n",
    "        index = index + 1\n",
    "    class_index = class_index + 1\n",
    "    dataset = np.concatenate((dataset, image_data), axis=0)\n",
    "    labelset = np.concatenate((labelset, image_label), axis=0)\n",
    " \n",
    "print(dataset.astype('uint8').dtype)\n",
    "print(labelset.astype('uint8').dtype)\n",
    " \n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
    "    dataset.astype('uint8'), labelset.astype('uint8'), test_size=0.25, random_state=42)\n",
    " \n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(\n",
    "    trainData, trainLabels, test_size=0.1, random_state=84)\n",
    " \n",
    "# Checking sizes of each data split\n",
    "print(\"training data points: {}\".format(len(trainLabels)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(testLabels)))\n",
    " \n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []\n",
    " \n",
    "# loop over kVals\n",
    "for k in range(1, 30, 2):\n",
    "    # train the classifier with the current value of `k`\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainData, trainLabels)\n",
    " \n",
    "    # evaluate the model and print the accuracies list\n",
    "    score = model.score(valData, valLabels)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    accuracies.append(score)\n",
    " \n",
    "# largest accuracy\n",
    "# np.argmax returns the indices of the maximum values along an axis\n",
    "i = np.argmax(accuracies)\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i],\n",
    "                                                                       accuracies[i] * 100))\n",
    " \n",
    "# Now that I know the best value of k, re-train the classifier\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "model.fit(trainData, trainLabels)\n",
    " \n",
    "# Predict labels for the test set\n",
    "predictions = model.predict(testData)\n",
    " \n",
    "# Evaluate performance of model for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))\n",
    "from PIL import Image\n",
    "for i in np.random.randint(0, high=len(testLabels), size=(5,)):\n",
    "    image = testData[i].reshape(1, -1)\n",
    "    prediction = model.predict(image)[0]\n",
    "    # show the prediction\n",
    "    print(\"I think that image is: {}\".format(r_lookup[prediction]))\n",
    "    #img = Image.fromarray(testData[i], 'RGB')\n",
    "    #img.save(i+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
