{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2]\n",
      "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "[10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3]\n",
      "[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8]\n",
      "[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n",
      "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
      " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4]\n",
      "[11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11]\n",
      "[12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12]\n",
      "[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1]\n",
      "uint8\n",
      "uint8\n",
      "training data points: 1432\n",
      "validation data points: 160\n",
      "testing data points: 531\n",
      "k=1, accuracy=84.38%\n",
      "k=3, accuracy=80.62%\n",
      "k=5, accuracy=78.75%\n",
      "k=7, accuracy=80.00%\n",
      "k=9, accuracy=78.12%\n",
      "k=11, accuracy=76.25%\n",
      "k=13, accuracy=73.12%\n",
      "k=15, accuracy=71.25%\n",
      "k=17, accuracy=70.62%\n",
      "k=19, accuracy=71.25%\n",
      "k=21, accuracy=71.25%\n",
      "k=23, accuracy=70.00%\n",
      "k=25, accuracy=69.38%\n",
      "k=27, accuracy=68.75%\n",
      "k=29, accuracy=70.00%\n",
      "k=1 achieved highest accuracy of 84.38% on validation data\n",
      "EVALUATION ON TESTING DATA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.95      0.90        20\n",
      "          2       0.94      1.00      0.97        30\n",
      "          3       0.99      0.95      0.97        79\n",
      "          4       1.00      0.65      0.79        20\n",
      "          5       1.00      0.87      0.93        54\n",
      "          6       0.85      0.83      0.84       118\n",
      "          7       1.00      0.91      0.96        47\n",
      "          8       0.94      0.84      0.89        19\n",
      "          9       0.63      0.84      0.72        55\n",
      "         10       1.00      0.50      0.67        12\n",
      "         11       0.90      0.98      0.94        46\n",
      "         12       0.81      0.97      0.88        31\n",
      "\n",
      "avg / total       0.90      0.88      0.88       531\n",
      "\n",
      "Image Name 217.png\n",
      "I think that image is: gloves\n",
      "Image Name 52.png\n",
      "I think that image is: tents\n",
      "Image Name 223.png\n",
      "I think that image is: hardshell_jackets\n",
      "Image Name 206.png\n",
      "I think that image is: hardshell_jackets\n",
      "Image Name 270.png\n",
      "I think that image is: crampons\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbor Classification\n",
    " \n",
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "#import imutils\n",
    "import cv2 as cv\n",
    "import os\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join,basename\n",
    " \n",
    "from PIL import Image\n",
    "desired_size = 128\n",
    " \n",
    "def process_image(old_im_pth):\n",
    "    im = Image.open(old_im_pth)\n",
    "    old_size = im.size\n",
    " \n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    " \n",
    "    im = im.resize(new_size, Image.ANTIALIAS)\n",
    " \n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size), (255, 225, 255))\n",
    "    new_im.paste(im, ((desired_size-new_size[0])//2,\n",
    "                      (desired_size-new_size[1])//2))\n",
    "    return np.array(new_im)\n",
    " \n",
    "#lookup = {'axes': 1, 'boots': 2, 'carabiners': 3, 'crampons': 4, 'gloves': 5,}\n",
    "#r_lookup = {1: 'axes', 2: 'boots', 3: 'carabiners', 4: 'crampons', 5: 'gloves'}\n",
    "lookup = {'axes': 1, 'boots': 2, 'carabiners': 3, 'crampons': 4, 'gloves': 5, 'hardshell_jackets': 6, 'harnesses': 7, 'helmets': 8, 'insulated_jackets': 9, 'pulleys': 10, 'rope': 11, 'tents': 12}\n",
    "r_lookup = {1: 'axes', 2: 'boots', 3: 'carabiners', 4: 'crampons', 5: 'gloves', 6: 'hardshell_jackets', 7: 'harnesses', 8: 'helmets', 9: 'insulated_jackets', 10: 'pulleys' , 11: 'rope', 12: 'tents'}\n",
    "img_root = '/home/team12/naresh/gear_images'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(\n",
    "    img_root) if os.path.isdir(os.path.join(img_root, o))]\n",
    "class_index = 1\n",
    "dataset = np.empty((1, desired_size * desired_size * 3))\n",
    "labelset = np.empty(1)\n",
    "for img_dir in img_dirs:\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    image_label = np.full([len(img_files)], lookup[basename(img_dir)])\n",
    "    print(image_label)\n",
    "    image_data = np.empty([len(img_files), desired_size * desired_size * 3])\n",
    "    index = 0\n",
    "    for img_file in img_files:\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        dst = np.zeros(shape=(desired_size, desired_size))\n",
    "        image = process_image(image_path)\n",
    "        norm_image = cv.normalize(image, dst, 0, 255, cv.NORM_MINMAX)\n",
    "        image_data[index] = norm_image.flatten()\n",
    "        # print(image_data.shape)\n",
    "        index = index + 1\n",
    "    class_index = class_index + 1\n",
    "    dataset = np.concatenate((dataset, image_data), axis=0)\n",
    "    labelset = np.concatenate((labelset, image_label), axis=0)\n",
    " \n",
    "print(dataset.astype('uint8').dtype)\n",
    "print(labelset.astype('uint8').dtype)\n",
    " \n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
    "    dataset.astype('uint8'), labelset.astype('uint8'), test_size=0.20, random_state=42)\n",
    " \n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(\n",
    "    trainData, trainLabels, test_size=0.1, random_state=84)\n",
    " \n",
    "# Checking sizes of each data split\n",
    "print(\"training data points: {}\".format(len(trainLabels)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(testLabels)))\n",
    " \n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []\n",
    " \n",
    "# loop over kVals\n",
    "for k in range(1, 30, 2):\n",
    "    # train the classifier with the current value of `k`\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainData, trainLabels)\n",
    " \n",
    "    # evaluate the model and print the accuracies list\n",
    "    score = model.score(valData, valLabels)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    accuracies.append(score)\n",
    " \n",
    "# largest accuracy\n",
    "# np.argmax returns the indices of the maximum values along an axis\n",
    "i = np.argmax(accuracies)\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i],\n",
    "                                                                       accuracies[i] * 100))\n",
    " \n",
    "# Now that I know the best value of k, re-train the classifier\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "model.fit(trainData, trainLabels)\n",
    " \n",
    "# Predict labels for the test set\n",
    "predictions = model.predict(testData)\n",
    " \n",
    "# Evaluate performance of model for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))\n",
    "from PIL import Image\n",
    "for i in np.random.randint(0, high=len(testLabels), size=(5,)):\n",
    "    image = testData[i]\n",
    "    prediction = model.predict(image.reshape(1, -1))[0]\n",
    "    # show the prediction\n",
    "    print(\"Image Name {}.png\".format(i))\n",
    "    print(\"I think that image is: {}\".format(r_lookup[prediction]))\n",
    "    #img = Image.fromarray(testData[i].reshape(128,128,3), 'RGB')\n",
    "    #img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from skimage import exposure\n",
    "import numpy as np\n",
    "#import imutils\n",
    "import cv2 as cv\n",
    "import os\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join,basename\n",
    "import matplotlib as plt\n",
    "from PIL import Image\n",
    " \n",
    "from PIL import Image\n",
    "desired_size = 128\n",
    " \n",
    "def process_image(old_im_pth):\n",
    "    im = Image.open(old_im_pth)\n",
    "    old_size = im.size\n",
    " \n",
    "    ratio = float(desired_size)/max(old_size)\n",
    "    new_size = tuple([int(x*ratio) for x in old_size])\n",
    " \n",
    "    im = im.resize(new_size, Image.ANTIALIAS)\n",
    " \n",
    "    new_im = Image.new(\"RGB\", (desired_size, desired_size), (255, 225, 255))\n",
    "    new_im.paste(im, ((desired_size-new_size[0])//2,\n",
    "                      (desired_size-new_size[1])//2))\n",
    "    return np.array(new_im)\n",
    " \n",
    "def normalize(image_path):\n",
    "    dst = np.zeros(shape=(desired_size, desired_size))\n",
    "    image = process_image(image_path)\n",
    "    norm_image = cv.normalize(image, dst, 0, 255, cv.NORM_MINMAX)\n",
    "    return norm_image.flatten()\n",
    " \n",
    "#lookup = {'axes': 1, 'boots': 2, 'carabiners': 3, 'crampons': 4, 'gloves': 5,}\n",
    "#r_lookup = {1: 'axes', 2: 'boots', 3: 'carabiners', 4: 'crampons', 5: 'gloves'}\n",
    "lookup = {'axes': 1, 'boots': 2, 'carabiners': 3, 'crampons': 4, 'gloves': 5, 'hardshell_jackets': 6, 'harnesses': 7, 'helmets': 8, 'insulated_jackets': 9, 'pulleys': 10, 'rope': 11, 'tents': 12}\n",
    "r_lookup = {1: 'axes', 2: 'boots', 3: 'carabiners', 4: 'crampons', 5: 'gloves', 6: 'hardshell_jackets', 7: 'harnesses', 8: 'helmets', 9: 'insulated_jackets', 10: 'pulleys' , 11: 'rope', 12: 'tents'}\n",
    "img_root = '/home/team12/naresh/gear_images'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(\n",
    "    img_root) if os.path.isdir(os.path.join(img_root, o))]\n",
    "class_index = 1\n",
    "dataset = np.empty((1, desired_size * desired_size * 3))\n",
    "labelset = np.empty(1)\n",
    "for img_dir in img_dirs:\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    image_label = np.full([len(img_files)], lookup[basename(img_dir)])\n",
    "    #print(image_label)\n",
    "    image_data = np.empty([len(img_files), desired_size * desired_size * 3])\n",
    "    index = 0\n",
    "    for img_file in img_files:\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        image_data[index] = normalize(image_path)\n",
    "        # print(image_data.shape)\n",
    "        index = index + 1\n",
    "    class_index = class_index + 1\n",
    "    dataset = np.concatenate((dataset, image_data), axis=0)\n",
    "    labelset = np.concatenate((labelset, image_label), axis=0)\n",
    " \n",
    "#print(dataset.astype('uint8').dtype)\n",
    "#print(labelset.astype('uint8').dtype)\n",
    " \n",
    "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
    "    dataset.astype('uint8'), labelset.astype('uint8'), test_size=0.25, random_state=42)\n",
    " \n",
    "(trainData, valData, trainLabels, valLabels) = train_test_split(\n",
    "    trainData, trainLabels, test_size=0.1, random_state=84)\n",
    " \n",
    "# Checking sizes of each data split\n",
    "print(\"training data points: {}\".format(len(trainLabels)))\n",
    "print(\"validation data points: {}\".format(len(valLabels)))\n",
    "print(\"testing data points: {}\".format(len(testLabels)))\n",
    " \n",
    "kVals = range(1, 30, 2)\n",
    "accuracies = []\n",
    " \n",
    "# loop over kVals\n",
    "for k in range(1, 30, 2):\n",
    "    # train the classifier with the current value of `k`\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(trainData, trainLabels)\n",
    " \n",
    "    # evaluate the model and print the accuracies list\n",
    "    score = model.score(valData, valLabels)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    accuracies.append(score)\n",
    " \n",
    "# largest accuracy\n",
    "# np.argmax returns the indices of the maximum values along an axis\n",
    "i = np.argmax(accuracies)\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (kVals[i],\n",
    "                                                                       accuracies[i] * 100))\n",
    " \n",
    "# Now that I know the best value of k, re-train the classifier\n",
    "model = KNeighborsClassifier(n_neighbors=kVals[i])\n",
    "model.fit(trainData, trainLabels)\n",
    " \n",
    "# Predict labels for the test set\n",
    "predictions = model.predict(testData)\n",
    " \n",
    "# Evaluate performance of model for each of the digits\n",
    "print(\"EVALUATION ON TESTING DATA\")\n",
    "print(classification_report(testLabels, predictions))\n",
    "\n",
    "for i in np.random.randint(0, high=len(testLabels), size=(5,)):\n",
    "    image = testData[i]\n",
    "    prediction = model.predict(image.reshape(1, -1))[0]\n",
    "    # show the prediction\n",
    "    print(\"Image Name {}.png\".format(i))\n",
    "    print(\"I think that image is: {}\".format(r_lookup[prediction]))\n",
    "    img = Image.fromarray(testData[i].reshape(128,128,3), 'RGB')\n",
    "    #img.save(\"{}.png\".format(i))\n",
    " \n",
    "test_image = normalize('/home/team12/naresh/test.jpeg')\n",
    "prediction = model.predict(test_image.reshape(1, -1))[0]\n",
    "print(\"I think that image is: {}\".format(r_lookup[prediction]))\n",
    "\n",
    "\n",
    "def showimage(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    plt.imshow(img)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
