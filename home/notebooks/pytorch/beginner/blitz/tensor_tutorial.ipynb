{
  "cells": [
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "\nWhat is PyTorch?\n================\n\nIt\u2019s a Python based scientific computing package targeted at two sets of\naudiences:\n\n-  A replacement for NumPy to use the power of GPUs\n-  a deep learning research platform that provides maximum flexibility\n   and speed\n\nGetting Started\n---------------\n\nTensors\n^^^^^^^\n\nTensors are similar to NumPy\u2019s ndarrays, with the addition being that\nTensors can also be used on a GPU to accelerate computing.\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "from __future__ import print_function\nimport torch"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Construct a 5x3 matrix, uninitialized:\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "x = torch.Tensor(5, 3)\nprint(x)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Construct a randomly initialized matrix:\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "x = torch.rand(5, 3)\nprint(x)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Get its size:\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "print(x.size())"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` is in fact a tuple, so it supports all tuple operations.</p></div>\n\nOperations\n^^^^^^^^^^\nThere are multiple syntaxes for operations. In the following\nexample, we will take a look at the addition operation.\n\nAddition: syntax 1\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "y = torch.rand(5, 3)\nprint(x + y)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Addition: syntax 2\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "print(torch.add(x, y))"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Addition: providing an output tensor as argument\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "result = torch.Tensor(5, 3)\ntorch.add(x, y, out=result)\nprint(result)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Addition: in-place\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# adds x to y\ny.add_(x)\nprint(y)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n    For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.</p></div>\n\nYou can use standard NumPy-like indexing with all bells and whistles!\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "print(x[:, 1])"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "x = torch.randn(4, 4)\ny = x.view(16)\nz = x.view(-1, 8)  # the size -1 is inferred from other dimensions\nprint(x.size(), y.size(), z.size())"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "**Read later:**\n\n\n  100+ Tensor operations, including transposing, indexing, slicing,\n  mathematical operations, linear algebra, random numbers, etc.,\n  are described\n  `here <http://pytorch.org/docs/torch>`_.\n\nNumPy Bridge\n------------\n\nConverting a Torch Tensor to a NumPy array and vice versa is a breeze.\n\nThe Torch Tensor and NumPy array will share their underlying memory\nlocations, and changing one will change the other.\n\nConverting a Torch Tensor to a NumPy Array\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "a = torch.ones(5)\nprint(a)"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "b = a.numpy()\nprint(b)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "See how the numpy array changed in value.\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "a.add_(1)\nprint(a)\nprint(b)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "Converting NumPy Array to Torch Tensor\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nSee how changing the np array changed the Torch Tensor automatically\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "import numpy as np\na = np.ones(5)\nb = torch.from_numpy(a)\nnp.add(a, 1, out=a)\nprint(a)\nprint(b)"
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": [
        "All the Tensors on the CPU except a CharTensor support converting to\nNumPy and back.\n\nCUDA Tensors\n------------\n\nTensors can be moved onto GPU using the ``.cuda`` method.\n\n"
      ]
    },
    {
      "execution_count": null,
      "cell_type": "code",
      "outputs": [],
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# let us run this cell only if CUDA is available\nif torch.cuda.is_available():\n    x = x.cuda()\n    y = y.cuda()\n    x + y"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "file_extension": ".py",
      "nbconvert_exporter": "python",
      "name": "python",
      "mimetype": "text/x-python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}