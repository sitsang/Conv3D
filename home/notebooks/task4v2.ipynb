{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/team12/team12/data/gear_images_normalized/axes : 0\n",
      "/home/team12/team12/data/gear_images_normalized/boots : 1\n",
      "/home/team12/team12/data/gear_images_normalized/carabiners : 2\n",
      "/home/team12/team12/data/gear_images_normalized/crampons : 3\n",
      "/home/team12/team12/data/gear_images_normalized/gloves : 4\n",
      "/home/team12/team12/data/gear_images_normalized/hardshell_jackets : 5\n",
      "/home/team12/team12/data/gear_images_normalized/harnesses : 6\n",
      "/home/team12/team12/data/gear_images_normalized/helmets : 7\n",
      "/home/team12/team12/data/gear_images_normalized/insulated_jackets : 8\n",
      "/home/team12/team12/data/gear_images_normalized/pulleys : 9\n",
      "/home/team12/team12/data/gear_images_normalized/rope : 10\n",
      "/home/team12/team12/data/gear_images_normalized/tents : 11\n",
      "(2122, 128, 128, 3)\n",
      "(2122,)\n",
      "Split...\n",
      "(1697, 128, 128, 3)\n",
      "(1697, 12)\n",
      "(425, 128, 128, 3)\n",
      "(425, 12)\n",
      "Start ...\n",
      "model step 1\n",
      "model step 2\n",
      "model step 3\n",
      "epoch:0\n",
      "Cost after epoch 0: 3.166725\n",
      "epoch:1\n",
      "Cost after epoch 1: 2.004362\n",
      "epoch:2\n",
      "Cost after epoch 2: 1.548947\n",
      "epoch:3\n",
      "Cost after epoch 3: 1.198862\n",
      "epoch:4\n",
      "Cost after epoch 4: 1.067594\n",
      "epoch:5\n",
      "Cost after epoch 5: 0.893757\n",
      "epoch:6\n",
      "Cost after epoch 6: 0.843330\n",
      "epoch:7\n",
      "Cost after epoch 7: 0.794928\n",
      "epoch:8\n",
      "Cost after epoch 8: 0.786151\n",
      "epoch:9\n",
      "Cost after epoch 9: 0.723801\n",
      "epoch:10\n",
      "Cost after epoch 10: 0.656201\n",
      "epoch:11\n",
      "Cost after epoch 11: 0.782500\n",
      "epoch:12\n",
      "Cost after epoch 12: 0.732856\n",
      "epoch:13\n",
      "Cost after epoch 13: 0.618530\n",
      "epoch:14\n",
      "Cost after epoch 14: 0.585915\n",
      "epoch:15\n",
      "Cost after epoch 15: 0.626685\n",
      "epoch:16\n",
      "Cost after epoch 16: 0.568144\n",
      "epoch:17\n",
      "Cost after epoch 17: 0.583157\n",
      "epoch:18\n",
      "Cost after epoch 18: 0.571945\n",
      "epoch:19\n",
      "Cost after epoch 19: 0.536121\n",
      "epoch:20\n",
      "Cost after epoch 20: 0.574800\n",
      "epoch:21\n",
      "Cost after epoch 21: 0.578833\n",
      "epoch:22\n",
      "Cost after epoch 22: 0.541705\n",
      "epoch:23\n",
      "Cost after epoch 23: 0.550100\n",
      "epoch:24\n",
      "Cost after epoch 24: 0.595106\n",
      "epoch:25\n",
      "Cost after epoch 25: 0.554287\n",
      "epoch:26\n",
      "Cost after epoch 26: 0.557030\n",
      "epoch:27\n",
      "Cost after epoch 27: 0.484595\n",
      "epoch:28\n",
      "Cost after epoch 28: 0.489927\n",
      "epoch:29\n",
      "Cost after epoch 29: 0.569692\n",
      "epoch:30\n",
      "Cost after epoch 30: 0.517398\n",
      "epoch:31\n",
      "Cost after epoch 31: 0.448885\n",
      "epoch:32\n",
      "Cost after epoch 32: 0.465160\n",
      "epoch:33\n",
      "Cost after epoch 33: 0.481404\n",
      "epoch:34\n",
      "Cost after epoch 34: 0.485147\n",
      "epoch:35\n",
      "Cost after epoch 35: 0.476772\n",
      "epoch:36\n",
      "Cost after epoch 36: 0.489534\n",
      "epoch:37\n",
      "Cost after epoch 37: 0.501997\n",
      "epoch:38\n",
      "Cost after epoch 38: 0.517140\n",
      "epoch:39\n",
      "Cost after epoch 39: 0.460342\n",
      "epoch:40\n",
      "Cost after epoch 40: 0.435388\n",
      "epoch:41\n",
      "Cost after epoch 41: 0.510628\n",
      "epoch:42\n",
      "Cost after epoch 42: 0.436950\n",
      "epoch:43\n",
      "Cost after epoch 43: 0.426383\n",
      "epoch:44\n",
      "Cost after epoch 44: 0.488627\n",
      "epoch:45\n",
      "Cost after epoch 45: 0.456427\n",
      "epoch:46\n",
      "Cost after epoch 46: 0.435280\n",
      "epoch:47\n",
      "Cost after epoch 47: 0.405890\n",
      "epoch:48\n",
      "Cost after epoch 48: 0.450196\n",
      "epoch:49\n",
      "Cost after epoch 49: 0.413255\n",
      "epoch:50\n",
      "Cost after epoch 50: 0.412519\n",
      "epoch:51\n",
      "Cost after epoch 51: 0.419897\n",
      "epoch:52\n",
      "Cost after epoch 52: 0.399416\n",
      "epoch:53\n",
      "Cost after epoch 53: 0.401947\n",
      "epoch:54\n",
      "Cost after epoch 54: 0.371434\n",
      "epoch:55\n",
      "Cost after epoch 55: 0.398825\n",
      "epoch:56\n",
      "Cost after epoch 56: 0.404034\n",
      "epoch:57\n",
      "Cost after epoch 57: 0.406256\n",
      "epoch:58\n",
      "Cost after epoch 58: 0.423144\n",
      "epoch:59\n",
      "Cost after epoch 59: 0.406789\n",
      "epoch:60\n",
      "Cost after epoch 60: 0.406206\n",
      "epoch:61\n",
      "Cost after epoch 61: 0.379237\n",
      "epoch:62\n",
      "Cost after epoch 62: 0.361373\n",
      "epoch:63\n",
      "Cost after epoch 63: 0.362416\n",
      "epoch:64\n",
      "Cost after epoch 64: 0.363547\n",
      "epoch:65\n",
      "Cost after epoch 65: 0.424070\n",
      "epoch:66\n",
      "Cost after epoch 66: 0.404655\n",
      "epoch:67\n",
      "Cost after epoch 67: 0.378600\n",
      "epoch:68\n",
      "Cost after epoch 68: 0.402326\n",
      "epoch:69\n",
      "Cost after epoch 69: 0.392938\n",
      "epoch:70\n",
      "Cost after epoch 70: 0.390551\n",
      "epoch:71\n",
      "Cost after epoch 71: 0.369510\n",
      "epoch:72\n",
      "Cost after epoch 72: 0.386807\n",
      "epoch:73\n",
      "Cost after epoch 73: 0.366054\n",
      "epoch:74\n",
      "Cost after epoch 74: 0.364330\n",
      "epoch:75\n",
      "Cost after epoch 75: 0.378137\n",
      "epoch:76\n",
      "Cost after epoch 76: 0.372808\n",
      "epoch:77\n",
      "Cost after epoch 77: 0.370659\n",
      "epoch:78\n",
      "Cost after epoch 78: 0.374566\n",
      "epoch:79\n",
      "Cost after epoch 79: 0.342495\n",
      "epoch:80\n",
      "Cost after epoch 80: 0.360661\n",
      "epoch:81\n",
      "Cost after epoch 81: 0.360943\n",
      "epoch:82\n",
      "Cost after epoch 82: 0.345236\n",
      "epoch:83\n",
      "Cost after epoch 83: 0.352748\n",
      "epoch:84\n",
      "Cost after epoch 84: 0.348597\n",
      "epoch:85\n",
      "Cost after epoch 85: 0.361109\n",
      "epoch:86\n",
      "Cost after epoch 86: 0.357463\n",
      "epoch:87\n",
      "Cost after epoch 87: 0.329052\n",
      "epoch:88\n",
      "Cost after epoch 88: 0.328814\n",
      "epoch:89\n",
      "Cost after epoch 89: 0.330705\n",
      "epoch:90\n",
      "Cost after epoch 90: 0.345438\n",
      "epoch:91\n",
      "Cost after epoch 91: 0.361220\n",
      "epoch:92\n",
      "Cost after epoch 92: 0.379022\n",
      "epoch:93\n",
      "Cost after epoch 93: 0.327156\n",
      "epoch:94\n",
      "Cost after epoch 94: 0.323374\n",
      "epoch:95\n",
      "Cost after epoch 95: 0.332426\n",
      "epoch:96\n",
      "Cost after epoch 96: 0.359348\n",
      "epoch:97\n",
      "Cost after epoch 97: 0.365985\n",
      "epoch:98\n",
      "Cost after epoch 98: 0.317103\n",
      "epoch:99\n",
      "Cost after epoch 99: 0.306949\n",
      "epoch:100\n",
      "Cost after epoch 100: 0.311832\n",
      "epoch:101\n",
      "Cost after epoch 101: 0.315955\n",
      "epoch:102\n",
      "Cost after epoch 102: 0.306945\n",
      "epoch:103\n",
      "Cost after epoch 103: 0.322698\n",
      "epoch:104\n",
      "Cost after epoch 104: 0.355039\n",
      "epoch:105\n",
      "Cost after epoch 105: 0.327583\n",
      "epoch:106\n",
      "Cost after epoch 106: 0.347459\n",
      "epoch:107\n",
      "Cost after epoch 107: 0.322859\n",
      "epoch:108\n",
      "Cost after epoch 108: 0.359887\n",
      "epoch:109\n",
      "Cost after epoch 109: 0.352752\n",
      "epoch:110\n",
      "Cost after epoch 110: 0.344090\n",
      "epoch:111\n",
      "Cost after epoch 111: 0.356112\n",
      "epoch:112\n",
      "Cost after epoch 112: 0.316566\n",
      "epoch:113\n",
      "Cost after epoch 113: 0.336816\n",
      "epoch:114\n",
      "Cost after epoch 114: 0.316991\n",
      "epoch:115\n",
      "Cost after epoch 115: 0.344802\n",
      "epoch:116\n",
      "Cost after epoch 116: 0.321951\n",
      "epoch:117\n",
      "Cost after epoch 117: 0.315856\n",
      "epoch:118\n",
      "Cost after epoch 118: 0.309970\n",
      "epoch:119\n",
      "Cost after epoch 119: 0.365487\n",
      "epoch:120\n",
      "Cost after epoch 120: 0.371080\n",
      "epoch:121\n",
      "Cost after epoch 121: 0.312454\n",
      "epoch:122\n",
      "Cost after epoch 122: 0.303823\n",
      "epoch:123\n",
      "Cost after epoch 123: 0.302913\n",
      "epoch:124\n",
      "Cost after epoch 124: 0.303611\n",
      "epoch:125\n",
      "Cost after epoch 125: 0.328822\n",
      "epoch:126\n",
      "Cost after epoch 126: 0.322184\n",
      "epoch:127\n",
      "Cost after epoch 127: 0.324430\n",
      "epoch:128\n",
      "Cost after epoch 128: 0.310858\n",
      "epoch:129\n",
      "Cost after epoch 129: 0.320762\n",
      "epoch:130\n",
      "Cost after epoch 130: 0.309764\n",
      "epoch:131\n",
      "Cost after epoch 131: 0.345065\n",
      "epoch:132\n",
      "Cost after epoch 132: 0.370271\n",
      "epoch:133\n",
      "Cost after epoch 133: 0.385374\n",
      "epoch:134\n",
      "Cost after epoch 134: 0.318335\n",
      "epoch:135\n",
      "Cost after epoch 135: 0.327492\n",
      "epoch:136\n",
      "Cost after epoch 136: 0.311170\n",
      "epoch:137\n",
      "Cost after epoch 137: 0.329756\n",
      "epoch:138\n",
      "Cost after epoch 138: 0.310250\n",
      "epoch:139\n",
      "Cost after epoch 139: 0.284390\n",
      "epoch:140\n",
      "Cost after epoch 140: 0.298803\n",
      "epoch:141\n",
      "Cost after epoch 141: 0.343434\n",
      "epoch:142\n",
      "Cost after epoch 142: 0.324679\n",
      "epoch:143\n",
      "Cost after epoch 143: 0.308991\n",
      "epoch:144\n",
      "Cost after epoch 144: 0.307275\n",
      "epoch:145\n",
      "Cost after epoch 145: 0.323522\n",
      "epoch:146\n",
      "Cost after epoch 146: 0.322393\n",
      "epoch:147\n",
      "Cost after epoch 147: 0.299776\n",
      "epoch:148\n",
      "Cost after epoch 148: 0.327608\n",
      "epoch:149\n",
      "Cost after epoch 149: 0.294695\n",
      "epoch:150\n",
      "Cost after epoch 150: 0.337303\n",
      "epoch:151\n",
      "Cost after epoch 151: 0.349449\n",
      "epoch:152\n",
      "Cost after epoch 152: 0.311674\n",
      "epoch:153\n",
      "Cost after epoch 153: 0.314807\n",
      "epoch:154\n",
      "Cost after epoch 154: 0.307130\n",
      "epoch:155\n",
      "Cost after epoch 155: 0.309975\n",
      "epoch:156\n",
      "Cost after epoch 156: 0.301765\n",
      "epoch:157\n",
      "Cost after epoch 157: 0.315542\n",
      "epoch:158\n",
      "Cost after epoch 158: 0.319281\n",
      "epoch:159\n",
      "Cost after epoch 159: 0.307679\n",
      "epoch:160\n",
      "Cost after epoch 160: 0.327555\n",
      "epoch:161\n",
      "Cost after epoch 161: 0.285718\n",
      "epoch:162\n",
      "Cost after epoch 162: 0.309726\n",
      "epoch:163\n",
      "Cost after epoch 163: 0.312686\n",
      "epoch:164\n",
      "Cost after epoch 164: 0.340313\n",
      "epoch:165\n",
      "Cost after epoch 165: 0.330482\n",
      "epoch:166\n",
      "Cost after epoch 166: 0.294030\n",
      "epoch:167\n",
      "Cost after epoch 167: 0.338511\n",
      "epoch:168\n",
      "Cost after epoch 168: 0.301951\n",
      "epoch:169\n",
      "Cost after epoch 169: 0.313978\n",
      "epoch:170\n",
      "Cost after epoch 170: 0.334359\n",
      "epoch:171\n",
      "Cost after epoch 171: 0.317907\n",
      "epoch:172\n",
      "Cost after epoch 172: 0.321200\n",
      "epoch:173\n",
      "Cost after epoch 173: 0.299483\n",
      "epoch:174\n",
      "Cost after epoch 174: 0.333979\n",
      "epoch:175\n",
      "Cost after epoch 175: 0.285230\n",
      "epoch:176\n",
      "Cost after epoch 176: 0.339340\n",
      "epoch:177\n",
      "Cost after epoch 177: 0.306716\n",
      "epoch:178\n",
      "Cost after epoch 178: 0.304991\n",
      "epoch:179\n",
      "Cost after epoch 179: 0.313678\n",
      "epoch:180\n",
      "Cost after epoch 180: 0.312161\n",
      "epoch:181\n",
      "Cost after epoch 181: 0.312621\n",
      "epoch:182\n",
      "Cost after epoch 182: 0.314697\n",
      "epoch:183\n",
      "Cost after epoch 183: 0.312772\n",
      "epoch:184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 184: 0.327205\n",
      "epoch:185\n",
      "Cost after epoch 185: 0.316903\n",
      "epoch:186\n",
      "Cost after epoch 186: 0.294316\n",
      "epoch:187\n",
      "Cost after epoch 187: 0.279125\n",
      "epoch:188\n",
      "Cost after epoch 188: 0.284372\n",
      "epoch:189\n",
      "Cost after epoch 189: 0.317354\n",
      "epoch:190\n",
      "Cost after epoch 190: 0.314625\n",
      "epoch:191\n",
      "Cost after epoch 191: 0.305610\n",
      "epoch:192\n",
      "Cost after epoch 192: 0.336450\n",
      "epoch:193\n",
      "Cost after epoch 193: 0.297109\n",
      "epoch:194\n",
      "Cost after epoch 194: 0.346216\n",
      "epoch:195\n",
      "Cost after epoch 195: 0.307971\n",
      "epoch:196\n",
      "Cost after epoch 196: 0.349032\n",
      "epoch:197\n",
      "Cost after epoch 197: 0.303628\n",
      "epoch:198\n",
      "Cost after epoch 198: 0.306043\n",
      "epoch:199\n",
      "Cost after epoch 199: 0.297627\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23e6928898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "Train Accuracy: 0.8791986\n",
      "Test Accuracy: 0.8329412\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n",
    "def create_placeholders(n_H0, n_W0, n_C0, n_y):\n",
    "    X = tf.placeholder(tf.float32, shape=(None, n_H0, n_W0, n_C0))\n",
    "    Y = tf.placeholder(tf.float32, shape=(None, n_y))\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)                              # so that your \"random\" numbers match ours\n",
    "        \n",
    "    W1 = tf.get_variable(\"W1\", [3, 3, 3, 32], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W2 = tf.get_variable(\"W2\", [3, 3, 32, 64], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "    W3 = tf.get_variable(\"W3\", [3, 3, 64, 128], initializer=tf.contrib.layers.xavier_initializer(seed=0))\n",
    "\n",
    "    parameters = {\"W1\": W1, \"W2\": W2, \"W3\": W3}\n",
    "    return parameters\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "\n",
    "    Z1 = tf.nn.conv2d(X, W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    Z1 = tf.layers.batch_normalization(Z1)\n",
    "    # add batch normalization\n",
    "    #Z1 = tf.nn.bias_add(Z1, tf.Variable(tf.random_normal([Z1.shape.as_list()[0]])))\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "\n",
    "    Z2 = tf.nn.conv2d(P1, W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    Z2 = tf.layers.batch_normalization(Z2)\n",
    "    # add batch normalization\n",
    "    #Z2 = tf.nn.bias_add(Z2, tf.Variable(tf.random_normal([Z2.shape.as_list()[0]])))\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    Z3 = tf.nn.conv2d(P2, W3, strides = [1,1,1,1], padding = 'SAME')\n",
    "    Z3 = tf.layers.batch_normalization(Z3)\n",
    "    # add batch normalization\n",
    "    #Z2 = tf.nn.bias_add(Z2, tf.Variable(tf.random_normal([Z2.shape.as_list()[0]])))\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    P3 = tf.nn.max_pool(A3, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    # add anohter layer\n",
    "\n",
    "    P4 = tf.nn.dropout(P3, 0.1)\n",
    "    P  = tf.contrib.layers.flatten(P4)\n",
    "    Z4 = tf.contrib.layers.fully_connected(P, 12, activation_fn=None)\n",
    "\n",
    "    return Z4\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z3, labels = Y))\n",
    "\n",
    "    return cost\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.01,\n",
    "          num_epochs=200, minibatch_size=64, print_cost=True):\n",
    "\n",
    "    print('model step 1')\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n",
    "    seed = 3                                          # to keep results consistent (numpy seed)\n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    print('model step 2')\n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    print('model step 3')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"epoch:\" + str(epoch))\n",
    "            \n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "                #print(\"minibatch:\" + str(minibatch))\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "            \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters\n",
    "    \n",
    "\n",
    "def random_mini_batches(X, Y, mini_batch_size = 128, seed = 0):\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation,:]\n",
    "    #shuffled_X, shuffled_Y = shuffle(X, Y, random_state=seed)\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#img_root = '/Users/zhigangyao/workspace/openhack/gear_images_normalized'\n",
    "img_root = '/home/team12/team12/data/gear_images_normalized'\n",
    "#img_root = '/home/team12/team12/data/gear_images_equalize'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(img_root) if os.path.isdir(os.path.join(img_root,o))]\n",
    "img_dirs.sort()\n",
    "x = []\n",
    "y = []\n",
    "category = 0\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir + \" : \" + str(category))\n",
    "    count = 0\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    for img_file in img_files:\n",
    "        #print(img_dir + '/' + img_file)\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        x.append(np.array(Image.open(image_path)))\n",
    "        y.append(category)\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "        count += 1\n",
    "    category += 1\n",
    "\n",
    "X = np.array(x)\n",
    "#Y = tf.one_hot(np.array(y), 12)\n",
    "Y = np.array(y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print('Split...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n",
    "#Y_train = tf.one_hot(y_train, 12)\n",
    "#Y_test = tf.one_hot(y_test, 12)\n",
    "Y_train = convert_to_one_hot(y_train, 12).T\n",
    "Y_test = convert_to_one_hot(y_test, 12).T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Start ...')\n",
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#img_root = '/Users/zhigangyao/workspace/openhack/gear_images_normalized'\n",
    "#img_root = '/home/team12/team12/data/gear_images_normalized'\n",
    "img_root = '/home/team12/team12/data/gear_images_equalize'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(img_root) if os.path.isdir(os.path.join(img_root,o))]\n",
    "img_dirs.sort()\n",
    "x = []\n",
    "y = []\n",
    "category = 0\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir + \" : \" + str(category))\n",
    "    count = 0\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    for img_file in img_files:\n",
    "        #print(img_dir + '/' + img_file)\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        x.append(np.array(Image.open(image_path)))\n",
    "        y.append(category)\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "        count += 1\n",
    "    category += 1\n",
    "\n",
    "X = np.array(x)\n",
    "#Y = tf.one_hot(np.array(y), 12)\n",
    "Y = np.array(y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print('Split...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n",
    "#Y_train = tf.one_hot(y_train, 12)\n",
    "#Y_test = tf.one_hot(y_test, 12)\n",
    "Y_train = convert_to_one_hot(y_train, 12).T\n",
    "Y_test = convert_to_one_hot(y_test, 12).T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Start ...')\n",
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#img_root = '/Users/zhigangyao/workspace/openhack/gear_images_normalized'\n",
    "img_root = '/home/team12/team12/data/gear_images_normalized'\n",
    "#img_root = '/home/team12/team12/data/gear_images_equalize'\n",
    "img_dirs = [os.path.join(img_root, o) for o in os.listdir(img_root) if os.path.isdir(os.path.join(img_root,o))]\n",
    "img_dirs.sort()\n",
    "x = []\n",
    "y = []\n",
    "category = 0\n",
    "for img_dir in img_dirs:\n",
    "    print(img_dir + \" : \" + str(category))\n",
    "    count = 0\n",
    "    img_files = [f for f in listdir(img_dir) if isfile(join(img_dir, f))]\n",
    "    for img_file in img_files:\n",
    "        #print(img_dir + '/' + img_file)\n",
    "        image_path = img_dir + '/' + img_file\n",
    "        x.append(np.array(Image.open(image_path)))\n",
    "        y.append(category)\n",
    "        #if count > 100:\n",
    "        #    break\n",
    "        count += 1\n",
    "    category += 1\n",
    "\n",
    "X = np.array(x)\n",
    "#Y = tf.one_hot(np.array(y), 12)\n",
    "Y = np.array(y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print('Split...')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=41)\n",
    "#Y_train = tf.one_hot(y_train, 12)\n",
    "#Y_test = tf.one_hot(y_test, 12)\n",
    "Y_train = convert_to_one_hot(y_train, 12).T\n",
    "Y_test = convert_to_one_hot(y_test, 12).T\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('Start ...')\n",
    "_, _, parameters = model(X_train, Y_train, X_test, Y_test)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
